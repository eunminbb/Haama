{
  "name": "haama",
  "publisher": "KKJ",
  "displayName": "Haama - 나만의 AI Coding 비서 (Codellama, Llama2, Synatra(한국어-KoLLM))",
  "description": "Haama는 AI Coding 비서로 코드 생성 및 디버깅을 혁신적으로 지원한다. 지원 모델: [Codellama:7B, Codellama:34B, Llama2, Synatra:7B(한국어-KoLLM)]. Import/export your conversation history. Bring up the assistant in a side pane by pressing cmd+shift+i.",
  "version": "1.0.4",
  "license": "MIT",
  "icon": "assets/hana2.png",
  "engines": {
    "vscode": "^1.77.0"
  },
  "repository": {
    "type": "git",
    "url": "https://github.com/eunminbb/Haama"
  },
  "categories": [
    "Other"
  ],
  "keywords": [
    "llama2",
    "codellama",
    "ollama",
    "ai",
    "agi",
    "artificial-intelligence",
    "natural-language-processing",
    "nlp",
    "language-model",
    "coding-assistant",
    "programming-help",
    "debugging",
    "questions",
    "code-generation"
  ],
  "activationEvents": [],
  "main": "./dist/extension.js",
  "contributes": {
    "commands": [
      {
        "command": "haama.start",
        "title": "Start Haama"
      },
      {
        "command": "haama.openSettings",
        "title": "Open Haama Settings"
      }
    ],
    "keybindings": [
      {
        "key": "cmd+shift+i",
        "command": "haama.start",
        "when": "editorTextFocus"
      }
    ],
    "configuration": {
      "title": "haama",
      "properties": {
        "haama.model": {
          "order": 0,
          "type": "string",
          "default": "codellama",
          "enum": [
            "codellama",
            "llama2",
            "synatra:7b"
          ],
          "enumDescriptions": [
            "CodeLlama:7B(Ollama)",
            "Llama2(Ollama)",
            "Synatra:7B(Ollama)"

          ],
          "description": "Select the AI model.",
          "scope": "window"
        },
        "haama.systemPrompt": {
          "order": 1,
          "type": "string",
          "default": "You are a helpful programming assistant running inside VS Code. The assistant always generates accurate and succinct messages. The assistant doesn't repeat previous information, and doesn't launch into long explanations unless asked. Important: Always provide code inside triple backticks.",
          "markdownDescription": "The 'system' prompt provided to the model. Keep in mind that some models pay stronger attention to the system prompt than others. For models that don't have a dedciated affordance for system prompts, this will be prepended to the first user prompt.",
          "scope": "window",
          "editorType": "string",
          "editorMultiline": true
        },
        "haama.maxLength": {
          "order": 2,
          "type": "integer",
          "default": 1000,
          "minimum": 1,
          "description": "Set the maximum length for the generated text (aka max_tokens).",
          "scope": "window"
        },
        "haama.temperature": {
          "order": 3,
          "type": "number",
          "default": 0,
          "maximum": 1,
          "minimum": 0,
          "description": "Set the temperature for controlling the randomness of the generated text.",
          "scope": "window"
        },
        "haama.highlightedCodeAwareness": {
          "order": 4,
          "type": "boolean",
          "default": false,
          "description": "[Experimental] Automatically include highlighted code in the prompt.",
          "scope": "window"
        },
        "haama.pressEnterToSend": {
          "order": 5,
          "type": "boolean",
          "default": false,
          "description": "When enabled, pressing enter will send the message in the input box. Shift + Enter will insert a new line. When this option is not selected, you must click the 'Send' button.",
          "scope": "window"
        }
      }
    }
  },
  "scripts": {
    "vscode:prepublish": "npm run package",
    "compile": "webpack",
    "watch": "webpack --watch",
    "package": "webpack --mode production --devtool hidden-source-map",
    "compile-tests": "tsc -p . --outDir out",
    "watch-tests": "tsc -p . -w --outDir out",
    "pretest": "npm run compile-tests && npm run compile && npm run lint",
    "lint": "eslint src --ext ts",
    "test": "node ./out/test/runTest.js"
  },
  "devDependencies": {
    "@types/glob": "^8.1.0",
    "@types/marked": "^4.0.8",
    "@types/mocha": "^10.0.1",
    "@types/node": "16.x",
    "@types/vscode": "^1.77.0",
    "@typescript-eslint/eslint-plugin": "^5.56.0",
    "@typescript-eslint/parser": "^5.56.0",
    "@vscode/test-electron": "^2.3.0",
    "eslint": "^8.36.0",
    "glob": "^8.1.0",
    "mocha": "^10.2.0",
    "ts-loader": "^9.4.2",
    "typescript": "^4.9.5",
    "webpack": "^5.76.3",
    "webpack-cli": "^5.0.1"
  },
  "dependencies": {
    "dotenv": "^16.0.3",
    "langchain": "^0.0.167",
    "marked": "^4.3.0",
    "openai": "^3.2.1"
  }
}
